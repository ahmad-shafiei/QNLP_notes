


import os
import warnings
import numpy as np
import matplotlib.pyplot as plt
from lambeq import (
    BobcatParser, RemoveCupsRewriter, AtomicType,
    IQPAnsatz, TketModel, BinaryCrossEntropyLoss,
    QuantumTrainer, SPSAOptimizer, Dataset
)
from pytket.extensions.qiskit import AerBackend
# Suppress warnings and parallel tokenizer messages
warnings.filterwarnings("ignore")
os.environ["TOKENIZERS_PARALLELISM"] = "false"
# Load and preprocess dataset
# -------------------------------
def read_data(filename):
    labels, sentences = [], []
    with open(filename) as f:
        for line in f:
            t = int(line[0])        # first char = label (0 or 1)
            labels.append([t, 1-t]) # encode as [1,0] or [0,1]
            sentences.append(line[1:].strip())
    return labels, sentences
train_labels, train_data = read_data('datasets/mc_train_data.txt')
dev_labels  , dev_data   = read_data('datasets/mc_dev_data.txt')
test_labels , test_data  = read_data('datasets/mc_test_data.txt')
# Parse sentences into diagrams
# -------------------------------
parser = BobcatParser(verbose='text')
remove_cups = RemoveCupsRewriter()

train_diagrams = [remove_cups(d) for d in parser.sentences2diagrams(train_data)]
dev_diagrams   = [remove_cups(d) for d in parser.sentences2diagrams(dev_data)]
test_diagrams  = [remove_cups(d) for d in parser.sentences2diagrams(test_data)]
# Convert diagrams into circuits
# -------------------------------
ansatz = IQPAnsatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 1},
                   n_layers=1, n_single_qubit_params=3)

train_circuits = [ansatz(d) for d in train_diagrams]
dev_circuits   = [ansatz(d) for d in dev_diagrams]
test_circuits  = [ansatz(d) for d in test_diagrams]
# Backend and model
# -------------------------------
backend = AerBackend()
backend_config = {
    'backend': backend,
    'compilation': backend.default_compilation_pass(2),
    'shots': 8192
}
all_circuits = train_circuits + dev_circuits + test_circuits
model = TketModel.from_diagrams(all_circuits, backend_config=backend_config)
# Training setup
# -------------------------------
bce = BinaryCrossEntropyLoss()
acc = lambda y_hat, y: np.sum(np.round(y_hat) == y) / len(y) / 2

BATCH_SIZE = 30
EPOCHS = 120

trainer = QuantumTrainer(
    model,
    loss_function=bce,
    epochs=EPOCHS,
    optimizer=SPSAOptimizer,
    optim_hyperparams={'a': 0.05, 'c': 0.06, 'A': 0.01 * EPOCHS},
    evaluate_functions={'acc': acc},
    evaluate_on_train=True,
    verbose='text',
    seed=2,
)
# Prepare datasets
# -------------------------------
train_dataset = Dataset(train_circuits, train_labels, batch_size=BATCH_SIZE)
val_dataset   = Dataset(dev_circuits, dev_labels, shuffle=False)

# Train
trainer.fit(train_dataset, val_dataset, log_interval=1)
## test
index=12
print(test_data[index])
print("\n")
prediction = model([test_circuits[index]])
print(prediction)
print("\n")
predicted_class = np.argmax(prediction)
print(f"The Class is assigned to : {predicted_class}")
print(f"The True Class Label is : {int(np.argmax(test_labels[index]))}")
print("Predicted class:", label_map[predicted_class])
print("Label=0 is for IT class and Label=1 is for Food class")
# Plot training curves
# -------------------------------
fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(
    2, 2, sharex=True, sharey='row', figsize=(10, 6)
)
ax_tl.set_title('Training set')
ax_tr.set_title('Development set')
ax_bl.set_xlabel('Iterations')
ax_br.set_xlabel('Iterations')
ax_bl.set_ylabel('Accuracy')
ax_tl.set_ylabel('Loss')
colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])
range_ = np.arange(1, trainer.epochs + 1)
ax_tl.plot(range_, trainer.train_epoch_costs, color=next(colours))
ax_bl.plot(range_, trainer.train_eval_results['acc'], color=next(colours))
ax_tr.plot(range_, trainer.val_costs, color=next(colours))
ax_br.plot(range_, trainer.val_eval_results['acc'], color=next(colours))






from preprocess import normalize_text, tokenize_text, \
                        merge_compound_verbs,label_roles #, detect_object_with_ra
txt1 = ' ?!!احمد غذا را خورد '
txt2 = 'رضا برنامه را ران گرفت'
#txt3 = 'علی کتاب را گرفت'   #  this example shows 'merge_compound_verbs' should be improve. 
txt1 = normalize_text(txt1)
txt2 = normalize_text(txt2)

tokens1= (tokenize_text(txt1))
tokens2= (tokenize_text(txt2))

print(tokenize_text(txt1))
print(merge_compound_verbs(tokens2))

print(label_roles(tokens1))




from preprocess import read_data
from pipeline_runner import dataset_to_diagrams_with_labels

labels, dataset = read_data("datasets/mc_train_data.txt", sep=" ")
# print("Loaded dataset:", dataset)

# diagrams, errors = dataset_to_diagrams_with_labels(dataset)

# print("First diagram+label:", diagrams)





from persian_cat_parser import PersianCatParser
from preprocess import read_data

train_labels, train_data = read_data("datasets/mc_train_data.txt")   # label [t 1-t]
dev_labels, dev_data     = read_data("datasets/mc_dev_data.txt")
test_labels, test_data   = read_data("datasets/mc_test_data.txt")

parser = PersianCatParser(verbose=True)

raw_train_diagrams = parser.sentences2diagrams(train_data)
raw_dev_diagrams   = parser.sentences2diagrams(dev_data)
raw_test_diagrams  = parser.sentences2diagrams(test_data)


# انتخاب یک جمله و نمایش ان
idx = 69  
sent = train_data[idx]
d = parser.sentence2diagram(sent)

print("Sentence:", sent)
print("Diagram:", d)


# print(train_data[14])
# raw_train_diagrams[14].draw()
import matplotlib.pyplot as plt
from matplotlib import rcParams

# معرفی فونت فارسی
rcParams['font.family'] = 'Tahoma'   # یا مثلاً 'Vazirmatn' اگر نصب باشه

raw_train_diagrams[14].draw()
plt.show()












from lambeq import RemoveCupsRewriter 

remove_cups = RemoveCupsRewriter()
train_diagrams = [remove_cups(diagram) for diagram in raw_train_diagrams]
dev_diagrams   = [remove_cups(diagram) for diagram in raw_dev_diagrams  ]
test_diagrams  = [remove_cups(diagram) for diagram in raw_test_diagrams ]


from lambeq import IQPAnsatz
from lambeq import AtomicType
ansatz = IQPAnsatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 1}, n_layers=1, n_single_qubit_params=3)
train_circuits = [ansatz(diagram) for diagram in train_diagrams]
dev_circuits   = [ansatz(diagram) for diagram in dev_diagrams  ]
test_circuits  = [ansatz(diagram) for diagram in test_diagrams ]


# -------------------------------
# Backend and model
# -------------------------------
from lambeq import TketModel
from pytket.extensions.qiskit import AerBackend

backend = AerBackend()
backend_config = {
    'backend': backend,
    'compilation': backend.default_compilation_pass(2),
    'shots': 8192
}
all_circuits = train_circuits + dev_circuits + test_circuits
model = TketModel.from_diagrams(all_circuits, backend_config=backend_config)


# -------------------------------
# Training setup
# -------------------------------
from lambeq import BinaryCrossEntropyLoss
from lambeq import QuantumTrainer, SPSAOptimizer
import numpy as np

bce = BinaryCrossEntropyLoss()
acc = lambda y_hat, y: np.sum(np.round(y_hat) == y) / len(y) / 2

BATCH_SIZE = 30
EPOCHS = 140

trainer = QuantumTrainer(
    model,
    loss_function=bce,
    epochs=EPOCHS,
    optimizer=SPSAOptimizer,
    optim_hyperparams={'a': 0.05, 'c': 0.06, 'A': 0.01 * EPOCHS},
    evaluate_functions={'acc': acc},
    evaluate_on_train=True,
    verbose='text',
    seed=2,
)


# -------------------------------
# Prepare datasets
# -------------------------------
from lambeq import Dataset
train_dataset = Dataset(train_circuits, train_labels, batch_size=BATCH_SIZE)
val_dataset   = Dataset(dev_circuits, dev_labels, shuffle=False)

# Train
trainer.fit(train_dataset, val_dataset, log_interval=1)


test_acc = acc(model(test_circuits), test_labels)
print('Test accuracy:', test_acc)


import matplotlib.pyplot as plt

fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(10, 6))
ax_tl.set_title('Training set')
ax_tr.set_title('Development set')
ax_bl.set_xlabel('Iterations')
ax_br.set_xlabel('Iterations')
ax_bl.set_ylabel('Accuracy')
ax_tl.set_ylabel('Loss')
colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])
range_ = np.arange(1, trainer.epochs + 1)
ax_tl.plot(range_, trainer.train_epoch_costs, color=next(colours))
ax_bl.plot(range_, trainer.train_eval_results['acc'], color=next(colours))
ax_tr.plot(range_, trainer.val_costs, color=next(colours))
ax_br.plot(range_, trainer.val_eval_results['acc'], color=next(colours))



# -------------------------------
# Example: classify a new sentence
# -------------------------------
label_map = {0: "Food Class", 1: "IT Class"}
new_sentence = ["زن غذا را خورد"]   # safer than "He runs the code"

# Parse and simplify
new_diagram = remove_cups(parser.sentence2diagram(new_sentence[0]))

# Diagram -> circuit
new_circuit = ansatz(new_diagram)

# Prediction
prediction = model([new_circuit])
predicted_class = np.argmax(prediction, axis=1)[0]

print("Sentence:", new_sentence[0])
print("Prediction (raw):", prediction)
print("Predicted class:", label_map[predicted_class])


index=23
print(test_data[index])
print("\n")
print(model([test_circuits[index]]))
print("\n")
print(f"The Class is assigned to : {np.argmax(model([test_circuits[index]]))}")
print(f"The True Class Label is : {int(np.argmax(test_labels[index]))}")   # for food label is 1 so --> [1 0]

print("Label=0 is for Food class and Label=1 is for IT class")



labels, sentences = read_data("datasets/mc_test_data.txt")
for i in range(5):
    print(sentences[i], labels[i])


from preprocess import normalize_text, tokenize_text, \
                        merge_compound_verbs,label_roles
from pipeline_runner import simple_pregroup_parser
# roles = label_roles(tokens2)
tokens = ['سارا', 'کتاب', 'را', 'خرید']

txt2 = 'رضا برنامه را ران گرفت'
txt2_n = normalize_text(txt2)
tokens2= (tokenize_text(txt2))

# roles = label_roles(tokens)
roles = label_roles(tokens2)
diagram = simple_pregroup_parser(roles)
print(diagram)








from pipeline_runner import sentence_to_diagram, dataset_to_diagrams

# txt = "سارا کتاب را خرید"

## جمله با فعل مرکب
txt = "علی برنامه را ران گرفت"    
diagram = sentence_to_diagram(txt)
print("Diagram:", diagram)

d = dataset_to_diagrams(txt)
print("Dataset diagrams:", d)











# -------------------------------
# Plot training curves
# -------------------------------
fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(
    2, 2, sharex=True, sharey='row', figsize=(10, 6)
)
ax_tl.set_title('Training set')
ax_tr.set_title('Development set')
ax_bl.set_xlabel('Iterations')
ax_br.set_xlabel('Iterations')
ax_bl.set_ylabel('Accuracy')
ax_tl.set_ylabel('Loss')

colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])
range_ = np.arange(1, trainer.epochs + 1)

ax_tl.plot(range_, trainer.train_epoch_costs, color=next(colours))
ax_bl.plot(range_, trainer.train_eval_results['acc'], color=next(colours))
ax_tr.plot(range_, trainer.val_costs, color=next(colours))
ax_br.plot(range_, trainer.val_eval_results['acc'], color=next(colours))



# -------------------------------
# Evaluate on test set
# -------------------------------
test_acc = acc(model(test_circuits), test_labels)
print("Test accuracy:", test_acc)



# -------------------------------
# Example: classify a new sentence
# -------------------------------
label_map = {0: "IT Class", 1: "Food Class"}
new_sentence = ["woman cooks dinner ."]   # safer than "He runs the code"

# Parse and simplify
new_diagram = remove_cups(parser.sentence2diagram(new_sentence[0]))

# Diagram -> circuit
new_circuit = ansatz(new_diagram)

# Prediction
prediction = model([new_circuit])
predicted_class = np.argmax(prediction, axis=1)[0]

print("Sentence:", new_sentence[0])
print("Prediction (raw):", prediction)
print("Predicted class:", label_map[predicted_class])











# cp *.txt datasets








import matplotlib.pyplot as plt

fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(10, 6))
ax_tl.set_title('Training set')
ax_tr.set_title('Development set')
ax_bl.set_xlabel('Iterations')
ax_br.set_xlabel('Iterations')
ax_bl.set_ylabel('Accuracy')
ax_tl.set_ylabel('Loss')

colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])
range_ = np.arange(1, trainer.epochs + 1)
ax_tl.plot(range_, trainer.train_epoch_costs, color=next(colours))
ax_bl.plot(range_, trainer.train_eval_results['acc'], color=next(colours))
ax_tr.plot(range_, trainer.val_costs, color=next(colours))
ax_br.plot(range_, trainer.val_eval_results['acc'], color=next(colours))

test_acc = acc(model(test_circuits), test_labels)
print('Test accuracy:', test_acc)





index=12
print(test_data[index])
print("\n")
prediction = model([test_circuits[index]])
print(prediction)
print("\n")
predicted_class = np.argmax(prediction)
print(f"The Class is assigned to : {predicted_class}")
print(f"The True Class Label is : {int(np.argmax(test_labels[index]))}")

print("Predicted class:", label_map[predicted_class])

print("Label=0 is for IT class and Label=1 is for Food class")


index=19
print(test_data[index])
print("\n")
print(model([test_circuits[index]]))
print("\n")
print(f"The Class is assigned to : {np.argmax(model([test_circuits[index]]))}")
print(f"The True Class Label is : {int(np.argmax(test_labels[index]))}")

print("Note that: Label=0 is for Food class and Label=1 is for IT class")


new_sentence = ["person debugs software ."]

# Parse
new_diagram = parser.sentence2diagram(new_sentence[0])
new_diagram = remove_cups(new_diagram)

# Convert to circuit
new_circuit = ansatz(new_diagram)

# Run through trained model
prediction = model([new_circuit])
print("Raw output:", prediction)

# Get predicted label
predicted_class = np.argmax(prediction, axis=1)[0]
print("Predicted class:", predicted_class)



# train_circuits[50].draw(figsize=(9, 9))
# tket_circuit = train_circuits[0].to_tk()
# train_circuits

# from pytket.circuit.display import render_circuit_jupyter, view_browser,render_circuit_as_html

# #render_circuit_jupyter(tket_circuit)
# 
# render_circuit_as_html(tket_circuit)
# train_circuits[0]
train_circuits[0].draw(figsize=(9, 9))





# from google.colab import drive
# drive.mount('/content/drive')
# !zip -r model_quantum_pipeline.zip runs
# !mv /content/model_quantum_pipeline.zip /content/drive/MyDrive/





import stanza

# Download a Stanza model (e.g., for English)
stanza.download('en')

# Initialize the pipeline
nlp = stanza.Pipeline('en')

# Process text
doc = nlp("This is a test sentence.")
print(doc)


import stanza

# Download the Persian model
stanza.download('fa')  # 'fa' is the language code for Persian

# Initialize the Persian pipeline
nlp = stanza.Pipeline('fa')

# Process a Persian text
doc = nlp("این یک جمله تستی است.")
print(doc)

# If you want to see tokens or lemmas:
for sentence in doc.sentences:
    for word in sentence.words:
        print(f"word: {word.text}\tlemma: {word.lemma}\tpos: {word.upos}")


import transformers
print(transformers.__version__)



